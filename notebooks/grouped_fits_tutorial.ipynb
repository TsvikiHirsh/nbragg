{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped/Gridded Data Fitting in nbragg\n",
    "\n",
    "This tutorial demonstrates how to analyze spatially-resolved or multi-sample neutron transmission data using nbragg's grouped fitting capabilities.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Loading Grouped Data](#loading)\n",
    "3. [Fitting Grouped Data](#fitting)\n",
    "4. [Visualizing Results](#visualization)\n",
    "5. [Accessing Individual Results](#individual)\n",
    "6. [Saving and Loading](#saving)\n",
    "7. [Advanced Features](#advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbragg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "nbragg supports three types of grouped data:\n",
    "\n",
    "- **2D Grids**: Spatially-resolved measurements on a regular grid (e.g., imaging data)\n",
    "- **1D Arrays**: Linear sequences of measurements (e.g., scan along a line)\n",
    "- **Named Groups**: Arbitrary collections with custom identifiers (e.g., different samples)\n",
    "\n",
    "All group types support:\n",
    "- Parallel fitting with `n_jobs` parameter\n",
    "- Flexible index access (tuples, integers, strings)\n",
    "- Parameter mapping and visualization\n",
    "- Save/load functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Grouped Data <a name=\"loading\"></a>\n",
    "\n",
    "### Creating Example Data\n",
    "\n",
    "For this tutorial, we'll create synthetic grouped data with varying thickness across a 2D grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory for example data\n",
    "tmp_dir = tempfile.mkdtemp()\n",
    "tmp_path = Path(tmp_dir)\n",
    "print(f\"Creating example data in: {tmp_path}\")\n",
    "\n",
    "# Generate 3x3 grid of measurements with varying properties\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # Create synthetic data with position-dependent thickness\n",
    "        channels = np.arange(100, 300)\n",
    "        # Thickness varies across the grid\n",
    "        thickness_variation = 1.0 + 0.2 * i + 0.1 * j\n",
    "        signal_counts = 1000 - channels * (2 * thickness_variation) + np.random.randint(-20, 20, len(channels))\n",
    "        signal_counts = np.maximum(signal_counts, 300)\n",
    "        \n",
    "        # Write signal file\n",
    "        signal_file = tmp_path / f\"signal_x{i}_y{j}.csv\"\n",
    "        with open(signal_file, 'w') as f:\n",
    "            f.write(\"channel,counts\\n\")\n",
    "            for ch, cnt in zip(channels, signal_counts):\n",
    "                f.write(f\"{ch},{cnt}\\n\")\n",
    "        \n",
    "        # Write openbeam file\n",
    "        ob_counts = 1000 + np.random.randint(-10, 10, len(channels))\n",
    "        ob_file = tmp_path / f\"ob_x{i}_y{j}.csv\"\n",
    "        with open(ob_file, 'w') as f:\n",
    "            f.write(\"channel,counts\\n\")\n",
    "            for ch, cnt in zip(channels, ob_counts):\n",
    "                f.write(f\"{ch},{cnt}\\n\")\n",
    "\n",
    "print(f\"Created {len(list(tmp_path.glob('signal_*.csv')))} signal files\")\n",
    "print(f\"Created {len(list(tmp_path.glob('ob_*.csv')))} openbeam files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading with Glob Patterns\n",
    "\n",
    "The most common way to load grouped data is using glob patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grouped data using glob patterns\n",
    "data = nbragg.Data.from_grouped(\n",
    "    signal=str(tmp_path / \"signal_*.csv\"),\n",
    "    openbeam=str(tmp_path / \"ob_*.csv\"),\n",
    "    L=10,  # sample-detector distance in meters\n",
    "    tstep=10e-6,  # time step in seconds\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded grouped data:\")\n",
    "print(f\"  Number of groups: {len(data.indices)}\")\n",
    "print(f\"  Group shape: {data.group_shape}\")\n",
    "print(f\"  Indices: {data.indices[:5]}...\")  # Show first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Loading Methods\n",
    "\n",
    "You can also load data from:\n",
    "- **Folders**: `Data.from_grouped(signal=\"path/to/signal_folder/\", openbeam=\"path/to/ob_folder/\")`\n",
    "- **File lists**: `Data.from_grouped(signal=[\"file1.csv\", \"file2.csv\"], openbeam=[...])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Grouped Data\n",
    "\n",
    "You can plot individual groups or view the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a specific group using tuple index\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "data.plot(index=(1, 1), ax=ax)\n",
    "ax.set_title(\"Transmission data for group (1, 1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access groups using string indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both formats work: \"(1,1)\" or \"(1, 1)\"\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "data.plot(index=\"(0,0)\", ax=ax1)  # No spaces\n",
    "data.plot(index=\"(2, 2)\", ax=ax2)  # With spaces\n",
    "ax1.set_title(\"Group (0, 0)\")\n",
    "ax2.set_title(\"Group (2, 2)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fitting Grouped Data <a name=\"fitting\"></a>\n",
    "\n",
    "### Basic Fitting\n",
    "\n",
    "Fitting grouped data works the same as single datasets, but with automatic parallel processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "xs = nbragg.CrossSection(iron=nbragg.materials[\"Fe_sg229_Iron-alpha\"])\n",
    "model = nbragg.TransmissionModel(xs, vary_basic=True)\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "print(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all groups in parallel\n",
    "result = model.fit(\n",
    "    data,\n",
    "    n_jobs=4,  # Use 4 parallel workers\n",
    "    progress_bar=True,  # Show progress\n",
    "    wlmin=1.5,\n",
    "    wlmax=5.0\n",
    ")\n",
    "\n",
    "print(f\"\\nFitting complete!\")\n",
    "print(f\"Number of fitted groups: {len(result.indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "View a comprehensive summary of all fit results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary DataFrame with all parameters and errors\n",
    "summary_df = result.summary()\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nSummary DataFrame (first 5 rows):\")\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Report (Jupyter)\n",
    "\n",
    "In Jupyter notebooks, you can display a formatted HTML summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display HTML report in Jupyter\n",
    "from IPython.display import HTML, display\n",
    "display(HTML(result.fit_report()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Results <a name=\"visualization\"></a>\n",
    "\n",
    "### Parameter Maps\n",
    "\n",
    "The most powerful visualization feature is parameter mapping. nbragg automatically detects the appropriate plot type based on your data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot thickness parameter map (auto-detects 2D heatmap for grid data)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "result.plot_parameter_map(\"thickness\", ax=ax, cmap=\"viridis\")\n",
    "ax.set_title(\"Thickness variation across sample\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot different parameters and include error bars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot norm parameter with errors\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "result.plot_parameter_map(\"norm\", ax=ax1, cmap=\"plasma\")\n",
    "ax1.set_title(\"Normalization parameter\")\n",
    "\n",
    "result.plot_parameter_map(\"norm\", plot_errors=True, ax=ax2, cmap=\"plasma\")\n",
    "ax2.set_title(\"Normalization errors\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering with Queries\n",
    "\n",
    "You can filter which groups to display using pandas query syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only groups where fit converged successfully\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "result.plot_parameter_map(\n",
    "    \"thickness\",\n",
    "    query=\"success == True and redchi < 2.0\",\n",
    "    ax=ax,\n",
    "    cmap=\"coolwarm\"\n",
    ")\n",
    "ax.set_title(\"Thickness (filtered: successful fits with χ² < 2)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Accessing Individual Results <a name=\"individual\"></a>\n",
    "\n",
    "You can access and analyze individual group results just like standard fit results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access result for a specific group\n",
    "single_result = result[(1, 1)]  # or result[\"(1,1)\"] or result[\"(1, 1)\"]\n",
    "\n",
    "print(f\"Result for group (1, 1):\")\n",
    "print(f\"  Success: {single_result.success}\")\n",
    "print(f\"  Reduced χ²: {single_result.redchi:.4f}\")\n",
    "print(f\"  Thickness: {single_result.params['thickness'].value:.4f} ± {single_result.params['thickness'].stderr:.4f}\")\n",
    "print(f\"  Norm: {single_result.params['norm'].value:.4f} ± {single_result.params['norm'].stderr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Individual Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit for a specific group\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "result.plot(index=(1, 1), ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stages Summary for Individual Groups\n",
    "\n",
    "If you used multi-stage fitting, you can view the stages summary for any group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View stages summary for a specific group (if multi-stage fitting was used)\n",
    "# stages_table = result.stages_summary(index=(1, 1))\n",
    "# print(stages_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Total Cross-Section\n",
    "\n",
    "View the total cross-section contribution for individual groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total cross-section for a specific group\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "result.plot_total_xs(index=(1, 1), plot_dspace=False, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and Loading <a name=\"saving\"></a>\n",
    "\n",
    "### Saving Grouped Results\n",
    "\n",
    "Save all grouped fit results to a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save grouped results\n",
    "result_file = tmp_path / \"grouped_results.json\"\n",
    "result.save(str(result_file))\n",
    "print(f\"Saved grouped results to {result_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Grouped Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grouped results\n",
    "loaded_result = nbragg.models.GroupedFitResult.load(str(result_file))\n",
    "\n",
    "print(f\"Loaded results:\")\n",
    "print(f\"  Number of groups: {len(loaded_result.indices)}\")\n",
    "print(f\"  Group shape: {loaded_result.group_shape}\")\n",
    "\n",
    "# Verify the loaded data matches\n",
    "print(f\"\\nVerifying loaded data...\")\n",
    "original_thickness = result[(1, 1)].params['thickness'].value\n",
    "loaded_thickness = loaded_result[(1, 1)].params['thickness'].value\n",
    "print(f\"Original thickness (1,1): {original_thickness:.6f}\")\n",
    "print(f\"Loaded thickness (1,1): {loaded_thickness:.6f}\")\n",
    "print(f\"Match: {np.isclose(original_thickness, loaded_thickness)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Features <a name=\"advanced\"></a>\n",
    "\n",
    "### Working with Named Groups\n",
    "\n",
    "For non-spatial data or custom groupings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create named group data\n",
    "named_dir = tmp_path / \"named_groups\"\n",
    "named_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for name in [\"sample_a\", \"sample_b\", \"sample_c\"]:\n",
    "    channels = np.arange(100, 300)\n",
    "    signal_counts = 1000 - channels * 2 + np.random.randint(-20, 20, len(channels))\n",
    "    signal_counts = np.maximum(signal_counts, 300)\n",
    "    \n",
    "    with open(named_dir / f\"{name}_signal.csv\", 'w') as f:\n",
    "        f.write(\"channel,counts\\n\")\n",
    "        for ch, cnt in zip(channels, signal_counts):\n",
    "            f.write(f\"{ch},{cnt}\\n\")\n",
    "    \n",
    "    ob_counts = 1000 + np.random.randint(-10, 10, len(channels))\n",
    "    with open(named_dir / f\"{name}_ob.csv\", 'w') as f:\n",
    "        f.write(\"channel,counts\\n\")\n",
    "        for ch, cnt in zip(channels, ob_counts):\n",
    "            f.write(f\"{ch},{cnt}\\n\")\n",
    "\n",
    "# Load named groups\n",
    "named_data = nbragg.Data.from_grouped(\n",
    "    signal=str(named_dir / \"*_signal.csv\"),\n",
    "    openbeam=str(named_dir / \"*_ob.csv\"),\n",
    "    L=10,\n",
    "    tstep=10e-6,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "print(f\"Named groups: {named_data.indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit named groups\n",
    "named_result = model.fit(named_data, n_jobs=2, progress_bar=False)\n",
    "\n",
    "# For named groups, parameter maps default to bar charts\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "named_result.plot_parameter_map(\"thickness\", ax=ax)\n",
    "ax.set_title(\"Thickness comparison across named samples\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Stage Fitting with Grouped Data\n",
    "\n",
    "You can use Rietveld-type multi-stage fitting with grouped data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stages for sequential refinement\n",
    "model.stages = {\n",
    "    'basic': ['norm', 'thickness'],\n",
    "    # Add more stages as needed\n",
    "}\n",
    "\n",
    "# Fit with stages\n",
    "staged_result = model.fit(data, stages='all', n_jobs=4, progress_bar=True)\n",
    "\n",
    "# View stages summary for a specific group\n",
    "# staged_result.stages_summary(index=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Grouped Datasets\n",
    "\n",
    "You can combine measurements from multiple runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two datasets with same group structure\n",
    "data1 = nbragg.Data.from_grouped(\n",
    "    signal=str(tmp_path / \"signal_*.csv\"),\n",
    "    openbeam=str(tmp_path / \"ob_*.csv\"),\n",
    "    L=10, tstep=10e-6, verbosity=0\n",
    ")\n",
    "\n",
    "data2 = nbragg.Data.from_grouped(\n",
    "    signal=str(tmp_path / \"signal_*.csv\"),\n",
    "    openbeam=str(tmp_path / \"ob_*.csv\"),\n",
    "    L=10, tstep=10e-6, verbosity=0\n",
    ")\n",
    "\n",
    "# Add them together (combines counts)\n",
    "combined_data = data1 + data2\n",
    "print(f\"Combined {len(combined_data.indices)} groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered:\n",
    "\n",
    "1. **Loading grouped data** from files using glob patterns, folders, or lists\n",
    "2. **Parallel fitting** with automatic worker management\n",
    "3. **Parameter mapping** with auto-detection of plot types\n",
    "4. **Individual result access** with flexible indexing\n",
    "5. **Saving/loading** grouped results\n",
    "6. **Advanced features** like named groups and multi-stage fitting\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Flexible indexing**: Access groups with tuples `(0, 0)`, strings `\"(0,0)\"` or `\"(0, 0)\"`, integers, or names\n",
    "- **Automatic parallelization**: Use `n_jobs` parameter for parallel fitting\n",
    "- **Smart visualization**: Auto-detects appropriate plot type (heatmap, line, bar) based on data structure\n",
    "- **Query filtering**: Use pandas queries to filter groups in visualizations\n",
    "- **Complete compatibility**: All standard methods (plot, stages_summary, plot_total_xs) work with grouped results\n",
    "\n",
    "### For More Information\n",
    "\n",
    "- See the [main nbragg tutorial](nbragg_tutorial.ipynb) for general fitting concepts\n",
    "- See the [Rietveld tutorial](Rietveld_in_nbragg_tutorial.ipynb) for multi-stage fitting\n",
    "- Check the [documentation](https://nbragg.readthedocs.io) for API reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temporary files\n",
    "import shutil\n",
    "shutil.rmtree(tmp_dir)\n",
    "print(\"Cleaned up temporary files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
